---
title: 如何优雅地编写Claude提示词——提示词工程介绍
date: 2025-04-06 20:00:49
tags: ['Claude','大模型','编程', 'LLM', 'AI', 'Prompt','人工智能','提示词']
categories: 探索发现
cover: https://b.bdstatic.com/comment/HPpFm-ziUYsgpwpjCcQ1VAa331303a4fbb9cd9a7d8cc627210df93.png
---

{% note info %}
注意：本文的提示词工程特别针对于 Claude 模型，对其他 LLM 的效果不作保证。
{% endnote %}

在使用大语言模型（例如Claude、ChatGPT、Deepseek等等）的时候，你有没有感觉大模型的回答经常答非所问、不听人话？即使在对话中指出了大模型的错误，大模型依然可能一边道歉、一遍继续坚持错误地回答，令人心力交瘁。这时你可能会觉得所谓的“AI浪潮”也不过是一群自媒体吹出来的新时代流量密码，实际用起来也就那样。

<img src="https://b.bdstatic.com/comment/HPpFm-ziUYsgpwpjCcQ1VA92f867d9070cbcfdd7ed5427f21d2f5e.png" width=250 />

但你有可能真的错怪大模型了。想象一下，当你被吩咐去做某件事时，通常是得到了一个“**指令**”，比如说：

> 你来为我写一段代码，实现输出“a + b”的功能

看上去是一个相当简单的功能，但是要用什么**语言**来实现？这个功能该包装成一个**方法**吗？`a` 和 `b` 是控制台**输入**的还是从别的地方**传递**过来的？在实际工作中这些疑问可能已经有了预设（或者通识），但对大模型来说就是不明不白的一句话了。指令就是我们通过对话框输入的“提示词（Prompt）”，面对一个不明不白的提示词，大模型也只能靠**猜测**给出回答：

<img src="https://b.bdstatic.com/comment/HPpFm-ziUYsgpwpjCcQ1VA82150011064efa643f3a74c576d9667b.png" title="Deepseek的猜测" />

```Python
# 输入两个数
a = float(input("请输入第一个数字："))
b = float(input("请输入第二个数字："))

# 计算并输出结果
print(f"{a} + {b} = {a + b}")
```

想要让大模型给出满意的答案，还得在提示词上多下功夫，这也是今天本文讨论的重点——**提示词工程**（Prompt Engineering）。

# 准备阶段
对于几乎任何一个任务来说都有所谓的“任务目标”存在，当任务目标被完成的时候，任务也就被完成了。在 Claude 提示词工程中，一个**明确的任务目标**是一个成功的提示词的基石。根据 Anthropic（Claude 的开发公司）官方文档的描述，可以从两个维度定义成功标准：

1. **具体的任务定义**：清楚地定义任务目标，不要使用模糊的语言。例如在前文的代码生成场景中，如果用户想得到一个 Python 函数，那么不仅要定义 “生成一个 Python 函数”，还要明确函数的输入输出格式、错误处理机制、性能要求（如时间复杂度）等。

2. **准确的评估指标**：明确的目标应该是可衡量的，尽可能用理性的数字来描述成果。我们可以为目标建立多维评估体系，包括：
    - 准确性：代码是否符合预期
    - 可读性：代码是否符合 PEP8 规范，命名是否符合预期
    - 效率：生成代码的时间复杂的和空间复杂度如何
    - 安全性：代码能否通过单元测试？是否存在 SQL 注入等安全漏洞

{% note orange 'fas fa-question' %}
**模棱两可的目标**：差不多、都行、感觉、可能、应该、尽量（到底是哪个？？）
{% endnote %}

另外需要明确的是：大模型虽然很强大，但也并非所有事情都能完成（~~例如证明黎曼猜想~~）。根据行业基准、先前实验、AI研究或专家知识设定你的目标，目标不应超出当前前沿模型的能力范围。

围绕两个基本维度，我们就可以开始编写提示词了。符合预期的提示词并不是一步得到的，而是不断与评估指标和和最终目标战斗的过程，直到所有指标都符合预期，一条提示词才最终出炉。

<img src="https://b.bdstatic.com/comment/HPpFm-ziUYsgpwpjCcQ1VA6caa57f647cc1f2720e1b1adc515d10b.png" title="Prompt开发流程" />

评估往往会进行多轮，由于可能涉及大量评分问题，可以考虑将评分的流程自动化（让 LLM 编写用例并打分等）。虽然自动化评估的准确度可能不如人工评分，但**数量优先于质量**，更多的自动评分问题（即使信号略低）比少量人工评分的高质量评估要好。

{% note green 'fas fa-lightbulb'%}
**LLM 评分技巧**

1. **详细、清晰的评分标准**：可以引入一个特定用例，甚至该用例的特定成功标准，可能需要几个评分标准来进行全面评估。例如：“答案应该总是在第一句话中提到‘Acme Inc.’。如果没有，答案自动评为‘不正确’。”
2. **明确具体的结果**：比如指示 LLM 只输出“{% label 正确 green %}”或“{% label 不正确 red %}”，或在 `1-5` 分范围内进行判断。纯定性评估难以快速和大规模评估。
3. **鼓励推理**：让 LLM 在决定评估分数之前先思考，然后丢弃推理过程。这可以提高评估性能，特别是对于需要复杂判断的任务。
{% endnote %}

# 提示词工程
看完上面的提示词开发流程，我们不免产生一个问题：最初的提示词应该如何编写呢？Anthropic 官方文档给出了帮助开发者快速搭建初版提示词的工具的 <a href="https://colab.research.google.com/drive/1SoAajN8CBYTl79VyTwxtxncfCWlHlyy9#scrollTo=Rj3kLi4ALGKf">Colab 在线文档</a>。这个工具需要付费调用 Claude 的 API，但我们可以看一看它的源码是如何实现的。

在文档中可以看到 Anthropic 为 Claude 编写的元提示词（Metaprompt），其中包含了六个用于解决各种任务的优秀提示词示例。在使用提示词工具时，用户需要声明自己的目标（即 `TASK`，如“根据评分标准对简历进行评分”），随后可以为目标附加多个预期变量（即 `VARIABLES`，如评分标准中的多个维度），接下来工具将会把任务插入到元提示词中执行得到预期的结果。

```TEXT
上面是六个用于解决各种任务的优秀提示词示例

That concludes the examples. Now, here is the task for which I would like you to write instructions:

<Task>
{{TASK}}   <- 两个花括号中的变量是可以动态替换的，这有助于形成Prompt模板，保持提问的一致性
</Task>

To write your instructions, follow THESE instructions:

下面是一些指令
```

直接阅读时会发现元提示中包含了大量标签、花括号、一些看上去像 markdown 语法的内容，这些都是 Anthropic 编写 Claude 提示词工程法则的实际应用。在接下来的文章中，我想介绍一下最近在项目中使用提示词工程的心得，包括**赋予角色**、**使用 xml 标签**、**采用提示词链**、**设置思维链**、**多样例提示**五大方案。

## 为 Claude 赋予角色
在对话中，则可以在对话开头加入对 Claude 的身份设置，例如：

> 您是一家世界500强科技公司的总法律顾问。


> 您是一位拥有数十年软件开发经验的开发工程师。


> ~~你是一个猫娘。~~

在使用 Claude 时，用户可以通过使用 `system` 参数来赋予大模型一个角色，也可以在对话中插入角色设置，从而显著提升回答表现。不要认为这一步很没必要，大模型是为通用场景设计的，一个合适的**角色定位**可以将 Claude 从一个通用助手转变为某个虚拟领域的专家。定制化角色还可以影响以下两个方面：

- **定制语气**：角色提示可以调整 Claude 的沟通风格。
- **提升专注度**：通过设置角色背景，Claude 能更好地保持在您任务特定要求的范围内。

在 API 中，可以使用 `system` 参数设置角色：

```Python
import anthropic

client = anthropic.Anthropic()

response = client.messages.create(
    model="claude-3-7-sonnet-20250219",
    max_tokens=2048,
    system="You are a seasoned data scientist at a Fortune 500 company.", # <-- 角色提示
    messages=[
        {"role": "user", "content": "Analyze this dataset for anomalies: <dataset>{{DATASET}}</dataset>"}
    ]
)

print(response.content)
```

## 使用 XML 标签
Anthropic 在官方文档中强调，XML 标签是提升 Claude 理解能力的关键工具。当提示词包含多个组件(如**上下文**、**指令**和**示例**)时，XML 标签可以形成结构化的提示词，帮助 Claude 更准确地对提示词进行**解析**，从而产生更高质量的输出，减少因误解提示词部分而导致的错误。

{% note green 'fas fa-lightbulb'%}
XML 标签和 HTML 标签长得很像，是通过一堆尖括号的形式来划分内容块的。我们可以通过标签来清晰地分割提示词的不同部分，这可以防止 Claude 混淆指令、示例和上下文。
用标签进行划分之后，我们也可以通过在提示词中引用特定标签的名称来**提取特定部分**进行响应。
{% endnote %}

一些常见的提示词块包括：
- 任务描述 \<task\>
- 任务介绍 \<instructions\>
- 格式化描述 \<formatting\>
- 思维链 \<thinking\>
- 样例 \<example\>
- 上下文 \<context\>
- 回答 \<answer\>

```text
<task>
您是一位资深游戏开发工程师，精通Unity引擎、Lua、C#、C++。现在需要您完成...
</task>
```

在实际使用的过程中，xml 标签给我的感受是提示词变得模块化，不仅 Claude 更容易理解，人读起来也舒服。

## 采用提示词链
在处理**复杂任务**时，如果你试图在单个提示中处理所有内容，Claude 有时可能会出错、或者遗漏某些关键步骤。**提示链**技术可以将复杂任务分解成更小、可管理的、有着明确单一目标的**子任务**，让模型从每个子任务入手，逐步完成整个复杂任务。提示链有以下好处：

- **准确性**：每个子任务都能得到 Claude 的充分关注，这样可以减少错误。
- **清晰度**：更简单的子任务意味着更清晰的指令和输出。
- **可追溯**：可以轻松定位和修复提示链中的问题。
​
如果 Claude 在回答中经常遗漏了某个步骤或者对某个步骤表现不佳，我们可以将该步骤单独放在一个提示中。这样你可以微调有问题的步骤，而无需重做整个任务。
​
你还可以用链式提示让 Claude 审查自己的工作，这被称作**自我纠正链**。自我纠正链可以捕获错误并改进输出，特别是对于一些高风险任务来说。

## 设置思维链
在处理复杂逻辑时，**思维链提示**（Chain-of-Thought，cot）可以引导 Claude 深度推理，能显著提升推理能力。思维链鼓励 Claude 逐步**分解问题**（尤其是在数学/逻辑/分析或复杂任务中），从而产生更准确和细致的输出、减少错误。

例如，在解决经典的 “两数之和” 问题时：

{% note orange 'fas fa-question' %}
**传统提示**
编写一个Python函数，输入整数列表和目标值，返回两个数的索引，使得它们的和等于目标值。
{% endnote %}

{% note green 'fas fa-lightbulb' %}
**思维链**

\<thinking\>
1. 遍历列表中的每个元素，记录其索引
2. 对于每个元素，计算目标值与当前元素的差值
3. 检查差值是否存在于后续元素中
4. 若存在，返回当前索引和差值的索引
5. 处理重复元素和边界情况

\</thinking\>

\<answer\>

在写代码之前在 \<thinking\> 标签中按分点进行思考。最后，在 \<answer\> 标签中使用你的分析编写符合要求的代码。
{% endnote %}

并非所有任务都需要引入思维链。引入思维链会增加输出长度和回答耗时，对简单任务来说可能是得不偿失的。

## 多示例提示
**示例**（Example）是让 Claude 精确生成你所需内容的秘密武器。通过在提示词中提供一些精心设计的示例，你可以显著提高 Claude 输出的准确性、一致性和质量。 这种技术被称为少样本或多示例提示（Few-Shot Prompting），对于需要结构化输出或遵循特定格式的任务特别有效。Anthropic 官方文档的 Tips 标明在提示词中可以包含 3-5 个多样化、相关的示例。对于复杂任务来说，**示例越多表现越好**，但也会增加提示词的长度和回答时间。

为了获得最大效果，请确保你的示例是：

- **相关性**：反映了实际用例，示例与目标之间的差距不应该太过遥远。
- **多样化**：示例应该涵盖边缘情况和潜在挑战，并且有足够的变化使 Claude 不会无意中捕捉到不必要的模式。
- **结构化**：示例最好用 \<example\> 标签来包装（如果有多个，则嵌套在 \<examples\> 标签中）以保持结构，让 Claude 能清楚明白哪些部分是示例。


随着 Claude 等大模型的不断进化，提示词工程正从经验驱动向科学方法论转变。掌握 Claude 提示词工程的核心技术，不仅能提升开发效率，更能解锁大模型的无限潜力。在未来的 AI 开发中，提示词工程将成为连接人类需求与机器智能的关键桥梁。